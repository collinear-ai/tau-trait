{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faaa4bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user with strategy: llm\n",
      "--------------------------------\n",
      "THE PROVIDER IS steer\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "THE TRAIT DICT IS {'impatience': 'high', 'confusion': 'low', 'skeptical': 'low', 'incoherence': 'low'}\n",
      "--------------------------------\n",
      "\n",
      "--------------------------------\n",
      "THE ENDPOINT IS https://steer.collinear.ai/steer_bare\n",
      "--------------------------------\n",
      "MESSAGE FROM STEER {'role': 'assistant', 'content': \"I just got my order and it's completely wrong.\"}\n",
      "Running tasks [4] (checkpoint path: test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "THE PROVIDER IS steer\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "THE TRAIT DICT IS {'impatience': 'high', 'confusion': 'low', 'skeptical': 'low', 'incoherence': 'low'}\n",
      "--------------------------------\n",
      "\n",
      "--------------------------------\n",
      "THE ENDPOINT IS https://steer.collinear.ai/steer_bare\n",
      "--------------------------------\n",
      "MESSAGE FROM STEER {'role': 'assistant', 'content': \"I've been charged for a late delivery of a package from your company, and I demand to speak to a manager!\"}\n",
      "Running task 4\n",
      "\n",
      "\n",
      "Instruction: You are Yusuf Rossi in 19122. You want to know how many tshirt options are available in the online store right now. You want to modify all your pending tshirts (i.e., your 2 relevant orders) to purple, s size, same v-neck, and prefer polyester. You are a private person that does not want to reveal much about yourself.\n",
      "\n",
      "--------------------------------\n",
      "THE ENDPOINT IS https://steer.collinear.ai/steer_bare\n",
      "--------------------------------\n",
      "MESSAGE FROM STEER {'role': 'assistant', 'content': \"I'm trying to order a tshirt online, can't you see my order history?!\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 1/1:   0%|          | 0/1 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "âŒ task_id=4 {'error': 'litellm.APIError: APIError: OpenAIException - Error code: 500', 'traceback': 'Traceback (most recent call last):\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/llms/openai.py\", line 825, in completion\\n    raise e\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/llms/openai.py\", line 784, in completion\\n    response = openai_client.chat.completions.create(**data, timeout=timeout)  # type: ignore\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\\n    return func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1147, in create\\n    return self._post(\\n           ^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\\n    raise self._make_status_error_from_response(err.response) from None\\nopenai.InternalServerError: Error code: 500\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/main.py\", line 1267, in completion\\n    raise e\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/main.py\", line 1240, in completion\\n    response = openai_chat_completions.completion(\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/llms/openai.py\", line 831, in completion\\n    raise OpenAIError(status_code=e.status_code, message=str(e))\\nlitellm.llms.openai.OpenAIError: Error code: 500\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sky/tau-bench-public/tau_trait/run.py\", line 85, in _run\\n    res = agent.solve(\\n          ^^^^^^^^^^^^\\n  File \"/home/sky/tau-bench-public/tau_trait/agents/tool_calling_agent.py\", line 49, in solve\\n    res = completion(\\n          ^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/utils.py\", line 959, in wrapper\\n    raise e\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/utils.py\", line 843, in wrapper\\n    result = original_function(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/main.py\", line 2607, in completion\\n    raise exception_type(\\n          ^^^^^^^^^^^^^^^\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/utils.py\", line 7586, in exception_type\\n    raise e\\n  File \"/home/sky/miniconda3/envs/tau_trait/lib/python3.11/site-packages/litellm/utils.py\", line 6016, in exception_type\\n    raise APIError(\\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Error code: 500\\n'}\n",
      "-----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtau_trait\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run\n\u001b[32m     10\u001b[39m config = RunConfig(\n\u001b[32m     11\u001b[39m     model_provider=\u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     user_model_provider=\u001b[33m\"\u001b[39m\u001b[33msteer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     endpoint=\u001b[33m\"\u001b[39m\u001b[33mhttps://steer.collinear.ai/steer_bare\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tau-bench-public/tau_trait/run.py:124\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    122\u001b[39m res = []\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     result = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     res.append(result)\n\u001b[32m    126\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tau_trait/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tau_trait/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from tau_trait.types import RunConfig\n",
    "from tau_trait.run import run\n",
    "from litellm import provider_list\n",
    "from tau_trait.envs.user import UserStrategy\n",
    "\n",
    "from tau_trait.types import RunConfig\n",
    "from tau_trait.run import run\n",
    "\n",
    "config = RunConfig(\n",
    "    model_provider=\"openai\",\n",
    "    user_model_provider=\"steer\",\n",
    "    model=\"gpt-4o\",\n",
    "    user_model=\"\", # steer api abstracts the model\n",
    "    num_trials=1,\n",
    "    env=\"retail\",\n",
    "    agent_strategy=\"tool-calling\",\n",
    "    temperature=0.7,\n",
    "    task_split=\"test\",\n",
    "    start_index=0,\n",
    "    end_index=-1,\n",
    "    task_ids=[4],\n",
    "    log_dir=\"results\",\n",
    "    max_concurrency=1,\n",
    "    seed=10,\n",
    "    shuffle=0,\n",
    "    user_strategy=\"llm\",\n",
    "    few_shot_displays_path=None,\n",
    "    trait_dict={\"impatience\": \"high\", \"confusion\": \"low\", \"skeptical\": \"low\", \"incoherence\": \"low\"},\n",
    "    result_fp=\"test\",\n",
    "    endpoint=\"https://steer.collinear.ai/steer_bare\"\n",
    ")\n",
    "\n",
    "run(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tau_trait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
